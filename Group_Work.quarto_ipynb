{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "bibliography: bio.bib\n",
        "csl: harvard-cite-them-right.csl\n",
        "title: Chocolate's Group Project\n",
        "assess:\n",
        "  group-date: '2024-12-17'\n",
        "execute:\n",
        "  echo: false\n",
        "  freeze: true\n",
        "format:\n",
        "  html:\n",
        "    code-copy: true\n",
        "    code-link: true\n",
        "    toc: true\n",
        "    toc-title: On this page\n",
        "    toc-depth: 2\n",
        "    toc_float:\n",
        "      collapsed: false\n",
        "      smooth_scroll: true\n",
        "  pdf:\n",
        "    include-in-header:\n",
        "      text: |\n",
        "        \\addtokomafont{disposition}{\\rmfamily}\n",
        "    mainfont: Spectral\n",
        "    sansfont: Roboto Flex\n",
        "    monofont: Liberation Mono\n",
        "    papersize: a4\n",
        "    geometry:\n",
        "      - top=25mm\n",
        "      - left=40mm\n",
        "      - right=30mm\n",
        "      - bottom=25mm\n",
        "      - heightrounded\n",
        "    toc: false\n",
        "    number-sections: false\n",
        "    colorlinks: true\n",
        "    highlight-style: github\n",
        "jupyter:\n",
        "  jupytext:\n",
        "    text_representation:\n",
        "      extension: .qmd\n",
        "      format_name: quarto\n",
        "      format_version: '1.0'\n",
        "      jupytext_version: 1.16.4\n",
        "  kernelspec:\n",
        "    display_name: Python (base)\n",
        "    language: python\n",
        "    name: base\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## 1. Who collected the InsideAirbnb data?\n",
        "\n",
        "::: {.duedate}\n",
        "\n",
        "( 2 points; Answer due Week 7 )\n",
        "\n",
        ":::\n",
        "\n",
        "The Inside Airbnb project, founded in 2014 by Murray Cox, who wanted to dispute Airbnb's claim that 87% of the hosts rent out the place in which they live [@Alsudais2021]. The project has benefited from the John Morris, who designed and refined the user experience, and Samantha Box, who supported coding and analysis while addressing key issues. Team members like Michael “Ziggy” Mintz and Anya Sophe Behn further enhanced automation and cloud migration [@insideairbnb]. Operating independently, the project equips policymakers, researchers, and communities to address Airbnb’s effects on housing and neighborhoods.\n",
        "\n",
        "## 2. Why did they collect the InsideAirbnb data?\n",
        "\n",
        "::: {.duedate}\n",
        "\n",
        "( 4 points; Answer due Week 7 )\n",
        "\n",
        ":::\n",
        "\n",
        "The Inside Airbnb project is a mission-driven initiative that provides data and advocacy on Airbnb's impact on residential communities[@insideairbnb]. The collected data offers a more transparent and critical perspective, enabling stakeholders to assess Airbnb's role in local economies, housing markets, and community dynamics. By analyzing Airbnb listings, the project helps policymakers, researchers, and communities better understand the impact of Airbnb on issues such as housing affordability, availability, gentrification, and displacement.\n",
        "\n",
        "## 3. How did they collect it?\n",
        "\n",
        "::: {.duedate}\n",
        "\n",
        "( 5 points; Answer due Week 8 )\n",
        "\n",
        ":::\n",
        "\n",
        "Inside Airbnb's data is extracted through web scraping technology from publicly available listing information on the Airbnb website. This process collects key details, including price, location, host information, and availability. To provide accurate and up-to-date insights, the data is regularly updated, with new information replacing previous records on a monthly basis [@prentice2024]. Additionally, Inside Airbnb estimates monthly occupancy rates and income based on historical data, providing market analysis, basic hospitality indicators, and information on the legal status of the short-term rental market. At the same time, Inside Airbnb integrates geospatial data through public GIS datasets to map community boundaries and analyze the local impact. The collected data is analyzed, cleaned, and aggregated to facilitate public discussion and support the analysis of short-term rental market trends, helping communities make informed decisions regarding short-term rental regulation.\n",
        "\n",
        "## 4. How does the method of collection (Q3) impact the completeness and/or accuracy of the InsideAirbnb data? How well does it represent the process it seeks to study, and what wider issues does this raise?\n",
        "\n",
        "::: {.duedate}\n",
        "\n",
        "( 11 points; Answer due Week 9 )\n",
        "\n",
        ":::\n",
        "Since InsideAirbnb provides property information and updates it monthly, it can, to some extent, represent the overall situation of the short-term rental market and assist in analyzing dynamic changes related to the time dimension. However, InsideAirbnb's data still has temporal limitations, and the publicly available data only reflects the content uploaded by hosts, which may contain false information or omissions, such as inaccurate reviews or misleading property descriptions. These issues may cause the data to fail to fully reflect the real market situation, thus affecting research based on InsideAirbnb data and further influencing the formulation of short-term rental market regulatory policies.\n",
        "\n",
        "## 5. What ethical considerations does the use of the InsideAirbnb data raise? \n",
        "\n",
        "::: {.duedate}\n",
        "\n",
        "( 18 points; Answer due {{< meta assess.group-date >}} )\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "## 6. With reference to the InsideAirbnb data (*i.e.* using numbers, figures, maps, and descriptive statistics), what does an analysis of Hosts and the types of properties that they list suggest about the nature of Airbnb lettings in London? \n",
        "\n",
        "::: {.duedate}\n",
        "\n",
        "( 15 points; Answer due {{< meta assess.group-date >}} )\n",
        "\n",
        ":::\n"
      ],
      "id": "c6da0b1f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# import packages\n",
        "import geopandas as gpd\n",
        "import os\n",
        "from requests import get\n",
        "from urllib.parse import urlparse\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from shapely.geometry import Point\n",
        "from esda import Moran, Moran_Local\n",
        "from libpysal.weights import Queen, KNN\n",
        "from splot.esda import moran_scatterplot, lisa_cluster\n",
        "from esda.moran import Moran\n",
        "from pyproj import Transformer\n",
        "from pyproj import CRS\n",
        "from mgwr.gwr import GWR\n",
        "from mgwr.sel_bw import Sel_BW\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import warnings\n",
        "pd.set_option('mode.chained_assignment', None)"
      ],
      "id": "75871b21",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "def cache_data(src:str, dest:str) -> str:\n",
        "    \"\"\"\n",
        "    Downloads a file from the given URL `src` and saves it to the `dest` directory.\n",
        "    If the file already exists and is of sufficient size, skips the download.\n",
        "    \n",
        "    Args:\n",
        "        src (str): The source URL of the file to be downloaded.\n",
        "        dest (str): The destination directory where the file will be saved.\n",
        "        \n",
        "    Returns:\n",
        "        str: The full path to the downloaded (or existing) file.\n",
        "    \"\"\"    \n",
        "    url = urlparse(src) # We assume that this is some kind of valid URL \n",
        "    fn  = os.path.split(url.path)[-1] # Extract the filename\n",
        "    dfn = os.path.join(dest,fn) # Destination filename\n",
        "    \n",
        "    if not os.path.isfile(dfn) or os.path.getsize(dfn) < 250:\n",
        "        \n",
        "        print(f\"{dfn} not found, downloading!\")\n",
        "\n",
        "        path = os.path.split(dest)\n",
        "        \n",
        "        if len(path) >= 1 and path[0] != '':\n",
        "            os.makedirs(os.path.join(*path), exist_ok=True)\n",
        "            \n",
        "        with open(dfn, \"wb\") as file:\n",
        "            response = get(src)\n",
        "            file.write(response.content)\n",
        "\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "    return dfn"
      ],
      "id": "ea6c6679",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# listing data,choose the data of 2024\n",
        "ymd  = '20240614'\n",
        "city = 'London'\n",
        "host = 'https://orca.casa.ucl.ac.uk'\n",
        "list_url  = f'{host}/~jreades/data/{ymd}-{city}-listings.parquet'\n",
        "transport_url = 'https://github.com/Chocolateyz/Chocolate/raw/refs/heads/main/Transport_Classification_of_Londoners_(TCoL)/Transport_Classification_of_Londoners_(TCoL).shp'\n",
        "inequity_url = 'https://github.com/Chocolateyz/Chocolate/raw/refs/heads/main/Borough_pages_data_UPDATE_9_2024_HACTAR(1).csv'\n",
        "pop_url = 'https://github.com/Chocolateyz/Chocolate/raw/refs/heads/main/population%20by%20borough.xlsx'\n",
        "sta_url = 'https://github.com/Chocolateyz/Chocolate/raw/refs/heads/main/London%20stations/London%20stations.shp'\n",
        "line_url = 'https://github.com/Chocolateyz/Chocolate/raw/refs/heads/main/London%20Train%20Lines/London%20Train%20Lines.shp'\n",
        "borough_url = 'https://github.com/Chocolateyz/Chocolate/raw/refs/heads/main/Boroughs.gpkg'"
      ],
      "id": "b0cb28b4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# the data frame of datas\n",
        "listing_df = pd.read_parquet(cache_data(list_url, os.path.join('data','raw')))\n",
        "# inequity data\n",
        "inequity = pd.read_csv(cache_data(inequity_url, os.path.join('data','raw')),skiprows=11, header=0)\n",
        "# population data\n",
        "pop = pd.read_excel(cache_data(pop_url, os.path.join('data','raw')))\n",
        "# borough outline\n",
        "borough = gpd.read_file(cache_data(borough_url, os.path.join('data','raw')))\n",
        "\n",
        "# station point data\n",
        "station = gpd.read_file(sta_url)\n",
        "# train line data\n",
        "line = gpd.read_file(line_url)\n",
        "# transport data, spatial unit is OA(output area)\n",
        "transport = gpd.read_file(transport_url)"
      ],
      "id": "798d1d85",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# this is the columns list, if you want to focus on a certain topic, choose some of them\n",
        "# listing data\n",
        "columns_list = listing_df.columns.to_list()\n",
        "# transport data\n",
        "columns_transport = transport.columns.to_list()\n",
        "# inequity data\n",
        "columns_inequity = inequity.columns.to_list()\n",
        "# population data\n",
        "columns_pop = pop.columns.to_list()\n",
        "# station data\n",
        "columns_station = station.columns.to_list()\n",
        "# line data\n",
        "columns_line = line.columns.to_list()\n",
        "# borough outline\n",
        "columns_borough = borough.columns.to_list()"
      ],
      "id": "cd82eec4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# what can be needed in listing\n",
        "airbnb_cols = [\n",
        "    'id', 'host_since', 'host_is_superhost', 'host_listings_count', 'host_total_listings_count',\n",
        "    'latitude', 'longitude', 'property_type', 'room_type', 'accommodates', 'price',\n",
        "    'minimum_nights', 'maximum_nights', 'availability_365', 'number_of_reviews'\n",
        "]\n",
        "\n",
        "airbnb_df = listing_df[airbnb_cols].copy()"
      ],
      "id": "08cb3655",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# price all NaN to '0' then str\n",
        "airbnb_df['price'] = airbnb_df['price'].fillna('0').astype(str)\n",
        "# price float\n",
        "airbnb_df['price'] = airbnb_df['price'].str.replace('£', '').str.replace(',', '').astype(float)\n",
        "\n",
        "# host since date\n",
        "airbnb_df['host_since'] = pd.to_datetime(airbnb_df['host_since'], errors='coerce')\n",
        "\n",
        "# superhost\n",
        "airbnb_df['host_is_superhost'] = listing_df['host_is_superhost']\n",
        "\n",
        "# delete NaN\n",
        "airbnb_df.dropna(subset=['price', 'latitude', 'longitude', 'host_since'], inplace=True)\n",
        "\n",
        "# NaN to 0\n",
        "airbnb_df.loc[:, 'host_listings_count'] = airbnb_df['host_listings_count'].fillna(0)\n",
        "airbnb_df.loc[:, 'host_total_listings_count'] = airbnb_df['host_total_listings_count'].fillna(0)\n",
        "airbnb_df.loc[:, 'number_of_reviews'] = airbnb_df['number_of_reviews'].fillna(0)"
      ],
      "id": "2d1ef58c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# Superhost Ratio\n",
        "superhost_ratio = airbnb_df['host_is_superhost'].value_counts(normalize=True)"
      ],
      "id": "774701d5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Host Analysis\n",
        "\n",
        "1.Host Listings Distribution: \n",
        "\n",
        "1.The majority of hosts own between 1 to 2 listings, with a few managing hundreds or even thousands of properties.\n",
        "\n",
        "2.The distribution highlights the presence of professional operators in London's Airbnb market, with the largest host managing over 3000 listings.\n",
        "\n",
        "2.Superhost Ratio: \n",
        "\n",
        "Only 16.6% of hosts are Superhosts, suggesting that while a small percentage of hosts maintain high service standards, the majority are casual or infrequent hosts.\n"
      ],
      "id": "b558bfdc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Listings per Host\n",
        "airbnb_df['host_listings_count'].plot(kind='hist', bins=30, ax=axes[0], color='skyblue')\n",
        "axes[0].set_title('Distribution of Host Listings Count')\n",
        "axes[0].set_xlabel('Number of Listings per Host')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "\n",
        "# Superhost Ratio\n",
        "superhost_ratio.plot(kind='bar', ax=axes[1], color=['orange', 'green'])\n",
        "axes[1].set_title('Superhost Ratio')\n",
        "axes[1].set_xlabel('Superhost Status')\n",
        "axes[1].set_ylabel('Count')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "142b62a0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Property Type Distribution and Room Type Distribution\n",
        "\n",
        "Property Type Distribution:\n",
        "\n",
        "1.The most common property types are \"Entire rental units\" and \"Private rooms in rental units\".\n",
        "\n",
        "2.This indicates a mix of properties catering to both tourists seeking entire apartments and budget-conscious travelers looking for private rooms.\n",
        "\n",
        "Room Type Distribution:\n",
        "\n",
        "1.63.7% of listings are entire homes/apartments, while 35.7% are private rooms.\n",
        "\n",
        "2.The dominance of entire homes suggests that Airbnb in London is often used for short-term vacation rentals rather than shared accommodation.\n"
      ],
      "id": "bc602983"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# property type counts\n",
        "property_counts = airbnb_df['property_type'].value_counts()\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
        "\n",
        "# visualize first 15s\n",
        "airbnb_df['property_type'].value_counts().head(15).plot(kind='bar', ax=axes[0], color='purple')\n",
        "axes[0].set_title('Top 15 Property Types')\n",
        "axes[0].set_xlabel('Property Type')\n",
        "axes[0].set_ylabel('Number of Listings')\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# room type\n",
        "room_type_counts = airbnb_df['room_type'].value_counts()\n",
        "\n",
        "airbnb_df['room_type'].value_counts().plot(kind='barh', ax=axes[1], color='green')\n",
        "axes[1].set_title('Room Type Distribution')\n",
        "axes[1].set_xlabel('Number of Listings')\n",
        "axes[1].set_ylabel('Room Type')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "e6abfb82",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Geographical Distribution\n",
        "\n",
        "Airbnb Listings Distribution:\n",
        "\n",
        "1.Listings are concentrated in central boroughs such as Westminster, Camden, and Kensington.\n",
        "\n",
        "2.This reflects high tourist demand in central London areas.\n",
        "\n",
        "Listings by Borough:\n",
        "\n",
        "1.Central boroughs have the highest density of listings, correlating with higher property prices and demand for short-term accommodation.\n",
        "\n",
        "2.Outer boroughs have fewer listings, indicating lower demand or fewer hosts in these regions.\n"
      ],
      "id": "e3051267"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "'''\n",
        "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
        "\n",
        "# Airbnb Listing\n",
        "borough.plot(ax=axes[0], edgecolor='black', facecolor='none', linewidth=1)\n",
        "airbnb_gdf.plot(ax=axes[0], markersize=1, alpha=0.5, color='royalblue')\n",
        "axes[0].set_title('Airbnb Listings in London with Borough Boundaries')\n",
        "axes[0].set_xlabel('Longitude')\n",
        "axes[0].set_ylabel('Latitude')\n",
        "\n",
        "# Airbnb with borough\n",
        "borough_final.plot(column='total_listings', cmap='Blues', legend=True, linewidth=0.5, edgecolor='black', ax=axes[1])\n",
        "axes[1].set_title('Airbnb Listings by Borough')\n",
        "axes[1].set_xlabel('Longitude')\n",
        "axes[1].set_ylabel('Latitude')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "'''"
      ],
      "id": "d01c0b0e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conclusion\n",
        "\n",
        "The analysis of hosts and property types in the InsideAirbnb data reveals that Airbnb lettings in London are characterized by:\n",
        "\n",
        "1.A significant proportion of professional hosts with multiple listings.\n",
        "\n",
        "2.A dominance of entire home/apartment rentals, catering to tourists and short-term visitors.\n",
        "\n",
        "3.Concentration in central boroughs with high demand for short-term rentals.\n",
        "\n",
        "4.Price points that reflect both budget and luxury options.\n",
        "\n",
        "## 7. Drawing on your previous answers, and supporting your response with evidence (*e.g.* figures, maps, EDA/ESDA, and simple statistical analysis/models drawing on experience from, e.g., CASA0007), how *could* the InsideAirbnb data set be used to inform the regulation of Short-Term Lets (STL) in London? \n",
        "\n",
        "::: {.duedate}\n",
        "\n",
        "( 45 points; Answer due {{< meta assess.group-date >}} )\n",
        "\n",
        ":::\n",
        "\n",
        "This section primarily explores the spatial differences of different property types and the social impacts brought by short-term rental density, using cluster analysis and geographically weighted regression. It also analyzes how such visualizations can inform the development of short-term rental (STL) regulation policies in London.\n",
        "\n",
        "### Cluster Analysis\n",
        "\n",
        "This approach uses price, accommodates, and room type to classify the property situation across different boroughs. \n",
        "\n",
        "First, the elbow curve is plotted to determine the number of clusters for classification, with the final choice being 3 clusters.\n"
      ],
      "id": "373dec1e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#Choose 'price','accommodates', 'room_type' as clustering variables\n",
        "data = listing_df[['price','accommodates', 'room_type', 'latitude', 'longitude']].copy()\n",
        "data = data.dropna()\n",
        "#Data cleansing (removal of outliers with a price of 0 or negative)\n",
        "data['price'] = data['price'].replace('[\\$,]', '', regex=True).astype(float) \n",
        "data = data[data['price'] > 0]  \n",
        "# Take the logarithm of the price to reduce the impact of extreme values\n",
        "data['log_price'] = np.log1p(data['price'])\n",
        "clustering_vars = ['log_price', 'accommodates', 'room_type']\n",
        "# Standardized numerical features and One-hot encoding category features\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), ['log_price', 'accommodates']),  \n",
        "        ('cat', OneHotEncoder(), ['room_type']) \n",
        "    ]\n",
        ")\n",
        "data_preprocessed = preprocessor.fit_transform(data)\n",
        "#Use the elbow method to select the optimal number of clusters\n",
        "'''\n",
        "sse = []\n",
        "k_range = range(2, 10) \n",
        "\n",
        "for k in k_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(data_preprocessed)\n",
        "    sse.append(kmeans.inertia_) \n",
        "# Draw the elbow method diagram\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(k_range, sse, marker='o')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Sum of Squared Errors (SSE)')\n",
        "plt.title('Elbow Method for Optimal k')\n",
        "plt.show()\n",
        "'''"
      ],
      "id": "193ee275",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The blue area in the final result represents the high-priced property zone. The price distribution in this area shows significant variation, with the presence of extremely high-priced properties. These properties are mostly large spaces, with 94.3% being entire homes and very few classified as private rooms or shared rooms. These areas are primarily concentrated in wealthier, high-end regions on the map, which are likely city centers or high-income residential areas. These characteristics align with the housing market trends of Central London, such as Westminster, Kensington and Chelsea, and the City of London. These regions are economically developed and serve as hotspots for the high-end rental market. However, this category is also distributed in peripheral areas like Harrow, Havering, and Croydon. This may be due to the prevalence of low-density residential properties on London’s outskirts, which are often rented as entire homes at relatively high prices. In particular, although Havering is generally a low-density residential area, a small number of newly developed or high-specification entire properties (e.g., villas or resort-style homes) can drive up prices, causing these areas to also fall into this category.\n",
        "\n",
        "The green area represents the low-priced property zone. The prices are significantly lower than those in the other two clusters. The properties are relatively small and primarily cater to individuals or couples. Most of these listings are private rooms, with a slightly higher proportion of shared rooms compared to the other clusters. These properties are typically located in Outer London, such as areas like Barking and Dagenham and Newham, where transportation is relatively convenient. However, rental demand mainly comes from budget-conscious tenants, such as students and solo travelers.\n",
        "\n",
        "The yellow area represents the medium-priced property zone. These properties are mostly medium-sized, suitable for small families or groups of three. They are typically located in Inner London, such as Hackney, Islington, and Southwark, forming a transitional zone.\n"
      ],
      "id": "3550b8d3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#K-means\n",
        "optimal_k = 3\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
        "data['cluster'] = kmeans.fit_predict(data_preprocessed)"
      ],
      "id": "31ea69ae",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "borough_url = 'https://github.com/Chocolateyz/Chocolate/raw/refs/heads/main/Boroughs.gpkg'\n",
        "boroughs = gpd.read_file(borough_url)"
      ],
      "id": "47a760e8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#Convert the CRS of Boroughs.gpkg from EPSG:27700 to EPSG:4326\n",
        "boroughs = boroughs.to_crs('EPSG:4326')\n",
        "#Create a GeoDataFrame containing latitude and longitude\n",
        "geo_data = gpd.GeoDataFrame(data, geometry=gpd.points_from_xy(data['longitude'], data['latitude']))\n",
        "geo_data = geo_data.set_crs('EPSG:4326', allow_override=True)\n",
        "# Delete the 'index_right' column that may already exist\n",
        "if 'index_right' in geo_data.columns:\n",
        "    geo_data = geo_data.drop(columns=['index_right'])\n",
        "if 'index_right' in boroughs.columns:\n",
        "    boroughs = boroughs.drop(columns=['index_right'])\n",
        "# Perform spatial join\n",
        "geo_data = gpd.sjoin(geo_data, boroughs, how='inner', predicate='within')\n",
        "# Merge 'cluster' column into 'boroughs' by clustering results\n",
        "boroughs = boroughs.join(geo_data['cluster'], how='left')"
      ],
      "id": "0ff4aa6f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "if 'index_right' in geo_data.columns:\n",
        "    geo_data = geo_data.drop(columns=['index_right'])\n",
        "if 'index_right' in boroughs.columns:\n",
        "    boroughs = boroughs.drop(columns=['index_right'])\n",
        "    \n",
        "geo_data = gpd.sjoin(geo_data, boroughs, how='inner', predicate='within')\n",
        "\n",
        "# Visualization\n",
        "boroughs.plot(\n",
        "    column='cluster', \n",
        "    cmap='Set3', \n",
        "      legend=False, \n",
        "    legend_kwds={'label': \"Cluster Types\", 'orientation': \"horizontal\"},\n",
        "    edgecolor='black',  \n",
        "    linewidth=0.5\n",
        ")\n",
        "plt.title('K-Means Clustering Result')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "id": "474c0838",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In summary, The blue area is primarily composed of high-end entire home rentals, characterized by extremely high prices and great diversity. Spatially, it may overlap with central London or upscale residential areas. The green area mainly consists of low-priced private rooms, catering to budget-conscious renters such as solo travelers or students. It is primarily located in outer or secondary market areas. The yellow area represents medium-priced rentals, mostly offering entire homes, suitable for small families or groups. Geographically, it has a broader distribution, with some overlap with tourist hotspot areas.\n",
        "\n",
        "### Regression Analysis\n",
        "\n",
        "The distribution of short-term rental properties may lead to a series of social effects. This section takes social inequality as an example to explore the impact of short-term rental distribution on social outcomes. By visualizing the spatial differences in these effects, the analysis reveals the varying urgency for policy intervention across different areas.\n",
        "\n",
        "Since factors such as economic conditions, population characteristics, and transportation accessibility may influence the distribution of short-term rentals—and these factors are not the focus of this study—their effects were removed from the independent variables.\n",
        "\n",
        "The factors selected to describe economic conditions, population characteristics, and transportation accessibility include poverty rate, population density, density of subway stations, and density of rail lines. Principal Component Analysis (PCA) was applied to extract the most representative components from these variables.\n",
        "\n",
        "The dependent variable chosen to represent social inequality is the 80:20 ratio of earnings, which indicates the level of income inequality within a given area. \n",
        "\n",
        "The variables derived from PCA were first used to model the density of short-term rentals. The residuals—representing the portion of variation potentially linked to other effects associated with short-term rental distribution—were then used as predictors for the social inequality variable. The analysis proceeded as follows:\n",
        "\n",
        "1.A global regression was performed using Ordinary Least Squares (OLS).\n",
        "\n",
        "2.Geographically Weighted Regression (GWR) was applied in the second step.\n"
      ],
      "id": "e7f5a126"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# Convert df to gdf\n",
        "listing_df['geometry'] = listing_df.apply(lambda row: Point(row['longitude'], row['latitude']), axis=1)\n",
        "listing_gdf = gpd.GeoDataFrame(listing_df, geometry='geometry', crs=\"EPSG:4326\")\n",
        "listing_gdf = listing_gdf.to_crs(epsg=27700)\n",
        "\n",
        "# select columns\n",
        "geo_list = listing_gdf[['name','geometry']]\n",
        "\n",
        "# Calculate the number of short-term rental data points contained in each borough\n",
        "joined_gdf = gpd.sjoin(geo_list, borough, how=\"inner\", predicate=\"within\")\n",
        "point_counts = joined_gdf.groupby('GSS_CODE').size().reset_index(name='point_count')\n",
        "#borough.set_index('GSS_CODE', inplace=True)\n",
        "#borough.reset_index(inplace=True)\n",
        "\n",
        "# add point count into borough\n",
        "borough_list = borough.merge(point_counts, on='GSS_CODE', how='left')\n",
        "\n",
        "# set zero if there is no point\n",
        "#borough_list['point_count'].fillna(0, inplace=True)"
      ],
      "id": "f078246a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# unify the coordinate system\n",
        "station = station.to_crs(epsg=27700)\n",
        "line = line.to_crs(epsg=27700)\n",
        "# Count the number of underground stations in each borough and join the result to the borough data\n",
        "station_join = gpd.sjoin(station, borough, how=\"inner\", predicate=\"within\")\n",
        "station_counts = station_join.groupby('GSS_CODE').size().reset_index(name='station_count')\n",
        "regression1 = borough_list.merge(station_counts,on='GSS_CODE', how='left')\n",
        "\n",
        "# Calculate the track length in each borough and join the result to the borough data\n",
        "line_join = gpd.sjoin(line, borough, how=\"inner\", predicate=\"within\")\n",
        "line_join['line_length'] = line_join.geometry.length\n",
        "lengths_per_borough = line_join.groupby('GSS_CODE')['line_length'].sum().reset_index()\n",
        "regression2 = regression1.merge(lengths_per_borough,on='GSS_CODE', how='left')\n",
        "# Standardize the format of borough names\n",
        "inequity['Area'] = inequity['Area'].str.replace('&','and')\n",
        "# Join the population and inequality index data together\n",
        "pop_inequity = pd.merge(pop, inequity, left_on='NAME', right_on='Area', how='left')\n",
        "# join all of the data\n",
        "regression3 = regression2.merge(pop_inequity,on='GSS_CODE', how='left')"
      ],
      "id": "f362fee0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# caculate densities\n",
        "regression4 = regression3[['GSS_CODE','Area','HECTARES','Poverty rate','station_count','line_length','POPULATION','point_count','80:20 ratio of earnings','geometry']]\n",
        "regression4['population_density'] = regression3['POPULATION'] / regression3['HECTARES']\n",
        "regression4['airbnb_density'] = regression3['point_count'] / regression3['HECTARES']\n",
        "regression4['station_density'] = regression3['station_count'] / regression3['HECTARES']\n",
        "regression4['line_density'] = regression3['line_length'] / regression3['HECTARES']\n",
        "# select columns for regression,remove NA\n",
        "regression_all = regression4.drop(columns=['POPULATION', 'HECTARES','point_count','station_count','line_length']).dropna()"
      ],
      "id": "69dd01da",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# Use short-term rental point data as the dependent variable, excluding the impacts of economy, population, and transportation\n",
        "X = regression_all.drop(columns=['geometry','airbnb_density','80:20 ratio of earnings','GSS_CODE','Area'])  # independent variables\n",
        "Y = regression_all['airbnb_density'] \n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "# Principal Component Analysis (PCA) to avoid multicollinearity.\n",
        "pca = PCA(n_components=0.95)  \n",
        "X_pca = pca.fit_transform(X_scaled)"
      ],
      "id": "a2fccadd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# Split the data into training and testing sets for linear fitting\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_pca, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# regression analysis\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "r2_train = model.score(X_train, Y_train)\n",
        "r2_test = model.score(X_test, Y_test)\n",
        "Y_pred_all = model.predict(X_pca)\n",
        "\n",
        "# Calculate the residuals for all boroughs\n",
        "residuals_all = Y - Y_pred_all"
      ],
      "id": "ddfa8d44",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# Get the coordinates (longitude, latitude) of the centroids of the geometries\n",
        "coords = regression_all.geometry.centroid.apply(lambda x: (x.x, x.y)).to_list()\n",
        "# Convert the list of coordinates into a NumPy array\n",
        "coords = np.array(coords)\n",
        "# Use the '80:20 ratio of earnings' as an indicator of inequality.\n",
        "# Extract the values of the '80:20 ratio of earnings' column as the dependent variable\n",
        "real_y = regression_all['80:20 ratio of earnings'].values \n",
        "# Choose residuals from the previous regression model as independent variable\n",
        "residuals = residuals_all.values "
      ],
      "id": "b64ab6e0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# Scale the residuals to standardize them\n",
        "scaler = StandardScaler()\n",
        "residuals_scaled = scaler.fit_transform(residuals.reshape(-1, 1))\n",
        "# Scale the real_y values to standardize them\n",
        "real_y_scaled = scaler.fit_transform(real_y.reshape(-1, 1))\n",
        "# Add a constant term\n",
        "X_loc = np.hstack([np.ones((residuals_scaled.shape[0], 1)), residuals_scaled])\n",
        "# Select the optimal bandwidth\n",
        "#selector = Sel_BW(coords=coords, y=real_y_scaled, X_loc=X_loc)\n",
        "#bandwidth = selector.search(criterion='AICc',bw_min=5, bw_max=15)"
      ],
      "id": "557e2767",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "bandwidth = 13\n",
        "#print(f\"Optimal bandwidth: {bandwidth}\")\n",
        "regression_data = np.column_stack([residuals_scaled, real_y_scaled])\n",
        "\n",
        "# Fit a Geographically Weighted Regression (GWR) model\n",
        "gwr_model = GWR(coords = coords, y=real_y_scaled, X = X_loc, bw = bandwidth)\n",
        "gwr_results = gwr_model.fit()"
      ],
      "id": "4c8e35a3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "'''\n",
        "# Define R² and Adjusted R² values for global regression and GWR regression\n",
        "global_r2 = 0.044\n",
        "global_adj_r2 = 0.010\n",
        "gwr_r2 = 0.523\n",
        "gwr_adj_r2 = 0.249\n",
        "\n",
        "# Create a dictionary to hold the regression results\n",
        "results_dict = {\n",
        "    \"Model Type\": [\"Global Regression\", \"GWR Regression\"],\n",
        "    \"R²\": [global_r2, gwr_r2],\n",
        "    \"Adjusted R²\": [global_adj_r2, gwr_adj_r2]\n",
        "}\n",
        "\n",
        "# Convert the dictionary to DataFrame\n",
        "results_df = pd.DataFrame(results_dict)\n",
        "\n",
        "# Create a figure and axis for the table visualization\n",
        "fig, ax = plt.subplots(figsize=(8,3))\n",
        "ax.axis('tight')\n",
        "ax.axis('off')\n",
        "table = ax.table(cellText=results_df.values, colLabels=results_df.columns, loc='center')\n",
        "\n",
        "# Customize the appearance of the table cells\n",
        "for (i, j), cell in table.get_celld().items():\n",
        "    cell.set_text_props(horizontalalignment='center', verticalalignment='center', fontsize=12,fontname='Source Serif 4')\n",
        "    if i == 0:\n",
        "        cell.set_fontsize(14)\n",
        "        cell.set_text_props(weight='bold')  \n",
        "        cell.set_facecolor((176/255, 224/255, 230/255, 0.5)) \n",
        "    else:\n",
        "        cell.set_facecolor((0.878, 1, 1,0.2))\n",
        "    cell.set_height(0.15)\n",
        "\n",
        "# Add title, adjust its position\n",
        "plt.title(\"R² Comparison Between Global Regression and GWR\", fontsize=14,fontname='Source Serif 4',y=0.8)\n",
        "# Display the table\n",
        "plt.show()\n",
        "'''\n",
        "\n",
        "# representing the local R square\n",
        "local_r2_values = gwr_results.localR2\n",
        "# Join the obtained local R² values back to the borough data\n",
        "regression_all['local_R2'] = local_r2_values\n",
        "r2_df = regression_all[['GSS_CODE','local_R2']]\n",
        "borough_r2 = borough.merge(r2_df,on = 'GSS_CODE', how='left')"
      ],
      "id": "030c8236",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By comparing the R² values of the GWR results across different boroughs, the geographical variation in the impact of short-term rental distribution on social inequality was assessed.\n",
        "\n",
        "The results reveal that certain boroughs, particularly in the central and western areas, such as Hammersmith and Fulham, display high R² values, reaching up to 0.7. This indicates that the independent variables explain 70% of the variation in the dependent variable. In contrast, boroughs such as Enfield and Waltham Forest exhibit R² values close to 0, suggesting that the effects of short-term rental distribution on social inequality vary significantly across regions.\n",
        "\n",
        "Taking Hammersmith and Fulham as an example, the R-squared value is notably high, and the coefficient is positive, indicating a significant positive correlation between the increase in short-term rental density and the rise in social inequality. This suggests that the impact of short-term rental distribution on income inequality is particularly pronounced in this area, underscoring the greater necessity for policy intervention. Measures such as setting limits on short-term rentals, increasing taxes and fees, and encouraging properties to return to the long-term rental market can be implemented. However, the specific measures to be taken require further analysis of the underlying causes of this high correlation.\n"
      ],
      "id": "99a69830"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# Convert the coordinate reference system\n",
        "borough_r2 = borough_r2.to_crs(epsg=4326)\n",
        "# Replace 'NA' values with NaN\n",
        "borough_r2['local_R2'] = borough_r2['local_R2'].replace('NA', np.nan)\n",
        "# Create a figure and axis for plotting\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "# Plot the borough data, using the 'local_R2' column to color the map.\n",
        "borough_r2.plot(column='local_R2', cmap='YlGnBu', legend=True,\n",
        "                missing_kwds={'color': 'gray', 'label': 'Missing values'},\n",
        "                legend_kwds={'label': \"Local R² Value\", 'orientation': \"horizontal\"},\n",
        "                ax=ax)\n",
        "borough_r2.boundary.plot(ax=ax, edgecolor='black', linewidth=0.3,alpha = 0.6)\n",
        "# Remove grid lines\n",
        "ax.grid(False)\n",
        "# Add title and label\n",
        "plt.title('Map of Local R² by Region',fontsize=16)\n",
        "plt.xlabel('Longitude',fontsize=14)\n",
        "plt.ylabel('Latitude',fontsize=14)\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "id": "6e123ecf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nevertheless, there are several issues and limitations in this analysis:\n",
        "\n",
        "1.The large spatial unit of the data may result in insufficient sample sizes, which can affect the stability and interpretability of the model's results.\n",
        "\n",
        "2.Missing data in some regions led to the absence of R² values in certain areas.\n",
        "\n",
        "3.Controlling for the influence of economic conditions, population, and transportation accessibility assumed linear effects, potentially overlooking nonlinear influences.\n",
        "\n",
        "4.The residuals, after accounting for economic, population, and transportation factors, may still include unaccounted external effects, meaning they do not solely represent the impact of short-term rental distribution.\n",
        "\n",
        "## References"
      ],
      "id": "4352d963"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (base)",
      "language": "python",
      "name": "base"
    },
    "jupytext": {
      "text_representation": {
        "extension": ".qmd",
        "format_name": "quarto",
        "format_version": "1.0",
        "jupytext_version": "1.16.4"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}